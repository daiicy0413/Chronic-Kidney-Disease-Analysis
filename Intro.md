# Chronic-Kidney-Disease-Analysis
The dataset on chronic kidney disease used in this project was obtained from Kaggle. Through multivariate analysis, it is possible to discern which variables are closely correlated with kidney failure. This analytical approach contributes to a deeper understanding of the disease and aids individuals in predicting and then preventing its onset.
The data comprise 26 columns, 400 observations, and variable types that are numeric and character. Figure 1 provides a data description.
1.  Import Necessary Packages: dplyr, dendextend, RColorBrewer, reshape2, ggthemes, GGally, hdrcde, KernSmooth, ggplot2, gridExtra, corrplot, wordcloud, wordcloud2, wesanderson, RColorBrewer, plotly, kernlab, vscc, caret, stringr. Then import data.
2. Data Cleaning. The data cleaning process involves removing the 'id' column, correcting incorrect values in categorical columns (e.g., replacing unwanted whitespace or tab characters in the 'dm', 'cad', and 'classification' columns), converting certain columns ('pcv', 'wc', 'rc') to numeric types, and changing the 'classification' column to a factor. Additionally, a quick check for missing values is performed.
3. Exploratory Data Analysis(EDA). Use Pairs Plot, Bar Plot and Pie Chart.
4. KNN:Choosing k via cross-validation, then we get k = 7.
5. Bagging (Bootstrap Aggregating):choose mtry=24, and by VarImpPlot, we can see the three most important variables are “specific_gravity”, “haemoglobin” and “serum_creatinine” (highest MeanDecreaseAccuracy); the two least important variables are “bacteria” and “white_blood_cell_count” (lowest MeanDecreaseAccuracy).
6. Random forest(extension of bagging):The 10-fold cross-validation gives us the best parameters is mtry = 2 and ntree = 100 with the lowest error of 0.006666667. Then we build Random Forest Model and by VarImpPlot, We can see the three most important variables are “haemoglobin”, “specific_gravity” and “packed_cell_volume”; the two least important variables are “bacteria” and “pus_cell_clump” (lowest MeanDecreaseAccuracy).
7. Logistic Regression Model: The reduced model demonstrates that variables “specific_gravity” and “serum_creatinine” have three asterisks which means they are significant at the 0.001 level. The variables “haemoglobin” and “packed_cell_volume” have two asterisks which means they are significant at the 0.01 level. In addition, the odd ratio tables show the estimated odd ratio and confidence intervals for each predictor variable. To conclude, the patient is more likely to get chronic kidney disease as the value of specific gravity, serum creatinine, haemoglobin and packed cell volume increases.
8. P-value, Adjusted Rand index (ARI) and the misclassification rate (MCR): all three ARIs are close to 1, where KNN and RandomForest appear the same as highest, and all the MCRs are pretty low. The p-value is 1.299745e-05, which quite low.
9. Conclusion: Throughout this project, we have deployed several machine learning algorithms to predict chronic kidney disease, conducting a thorough analysis of their efficacy. Meticulous data preprocessing, application of algorithms, and performance evaluation revealed that the k-Nearest Neighbors, Bagging, and Random Forest methods all demonstrated high precision in predicting chronic kidney disease. The calculated Adjusted Rand Index and Misclassification Rate results indicated the effectiveness of our chosen models in handling this type of medical data. 
